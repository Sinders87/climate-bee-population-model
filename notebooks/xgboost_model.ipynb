{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eddfb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ML Model Training (Step 2: XGBoost) ---\n",
      "Loaded master dataset with 378 rows.\n",
      "Prepared data: Using 249 complete rows for modeling.\n",
      "Features (X) selected: ['inventory_colonies', 'stressor_disease_pct', 'stressor_other_pct', 'stressor_pesticides_pct', 'stressor_pests_pct', 'stressor_unknown_pct', 'stressor_varroa_mites_pct', 'annual_avg_temp', 'annual_total_precip', 'annual_avg_ndvi', 'annual_total_sightings']\n",
      "Data split into training (80%) and testing (20%) sets.\n",
      "Training the XGBoost model...\n",
      "Model training complete.\n",
      "\n",
      "--- ✅ XGBoost MODEL EVALUATION ---\n",
      "R-squared (R²): 0.374\n",
      "Mean Absolute Error (MAE): 2.403 (percentage points)\n",
      "\n",
      "--- Baseline Model Comparison ---\n",
      "Baseline R²: 0.488  |  New XGBoost R²: 0.374\n",
      "Baseline MAE: 2.115 |  New XGBoost MAE: 2.403\n",
      "\n",
      "--- XGBoost FEATURE IMPORTANCE ---\n",
      "The most important factors (according to XGBoost):\n",
      "                      Feature  Importance\n",
      "2          stressor_other_pct    0.246529\n",
      "6   stressor_varroa_mites_pct    0.105621\n",
      "9             annual_avg_ndvi    0.098500\n",
      "10     annual_total_sightings    0.094119\n",
      "8         annual_total_precip    0.081930\n",
      "7             annual_avg_temp    0.077684\n",
      "4          stressor_pests_pct    0.074274\n",
      "0          inventory_colonies    0.061874\n",
      "5        stressor_unknown_pct    0.060836\n",
      "3     stressor_pesticides_pct    0.050135\n",
      "1        stressor_disease_pct    0.048498\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Starting ML Model Training (Step 2: XGBoost) ---\")\n",
    "\n",
    "# Load the Master Dataset\n",
    "try:\n",
    "    df_master = pd.read_csv('../data/master_dataset_state_year.csv')\n",
    "    print(f\"Loaded master dataset with {len(df_master)} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Could not find 'master_dataset_state_year.csv'.\")\n",
    "    raise SystemExit()\n",
    "\n",
    "# Prepare Data for Modeling\n",
    "df_model = df_master.dropna().copy()\n",
    "print(f\"Prepared data: Using {len(df_model)} complete rows for modeling.\")\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "y = df_model['loss_pct']\n",
    "X = df_model.drop(columns=['year', 'state', 'loss_pct'])\n",
    "\n",
    "print(f\"Features (X) selected: {list(X.columns)}\")\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Data split into training (80%) and testing (20%) sets.\")\n",
    "\n",
    "# Train the XGBoost Model\n",
    "print(\"Training the XGBoost model...\")\n",
    "# Prevent the model from overfitting\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=500, \n",
    "    early_stopping_rounds=10, \n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Find the best stopping point\n",
    "model_xgb.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\n--- ✅ XGBoost MODEL EVALUATION ---\")\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "r2_xgb = r2_score(y_test, y_pred)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R-squared (R²): {r2_xgb:.3f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_xgb:.3f} (percentage points)\")\n",
    "\n",
    "print(\"\\n--- Baseline Model Comparison ---\")\n",
    "print(f\"Baseline R²: 0.488  |  New XGBoost R²: {r2_xgb:.3f}\")\n",
    "print(f\"Baseline MAE: 2.115 |  New XGBoost MAE: {mae_xgb:.3f}\")\n",
    "\n",
    "# Show Feature Importance\n",
    "print(\"\\n--- XGBoost FEATURE IMPORTANCE ---\")\n",
    "importances = model_xgb.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"The most important factors (according to XGBoost):\")\n",
    "print(importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
